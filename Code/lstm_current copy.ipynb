{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === DATA PREPARATION ===\n",
    "print(\"[INFO] Starting data preparation...\")\n",
    "\n",
    "# Load preprocessed sentences\n",
    "preprocessed_file_path = '../Data/train/preprocessed_sentences.json'\n",
    "with open(preprocessed_file_path, 'r') as f:\n",
    "    preprocessed_data = json.load(f)\n",
    "print(\"[INFO] Loaded preprocessed sentences.\")\n",
    "\n",
    "# Load the saved tokenizer to use its vocabulary size\n",
    "with open('../Data/train/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Load max_seq_length\n",
    "with open('../Data/train/max_seq_length.pkl', 'rb') as f:\n",
    "    max_seq_length = pickle.load(f)\n",
    "\n",
    "print(len(preprocessed_data))\n",
    "\n",
    "preprocessed_data = preprocessed_data[0:100]\n",
    "\n",
    "# Extract the preprocessed sequences directly\n",
    "Y_data = [item['PREPROCESSED_SENTENCE'] for item in preprocessed_data]\n",
    "\n",
    "# Adjust for decoder input and target\n",
    "decoder_input_data = np.array(Y_data)[:, :-1]\n",
    "decoder_target_data = np.array(Y_data)[:, 1:]\n",
    "\n",
    "# Load video features from the directory\n",
    "feature_dir = '../Data/train/features'\n",
    "print(\"[INFO] Video features directory set.\")\n",
    "\n",
    "video_features = []\n",
    "for item in preprocessed_data:\n",
    "    file_path = os.path.join(feature_dir, f\"{item['SENTENCE_NAME']}.json\")\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            video_features.append(json.load(f))\n",
    "        print(len(video_features))\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load: {file_path}. Error: {e}\")\n",
    "\n",
    "print(len(video_features))\n",
    "print(len(preprocessed_data))\n",
    "\n",
    "print(\"[INFO] Loaded video features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "max_frames = max([len(features) for features in video_features])\n",
    "feature_length = len(video_features[0]['frame_0'][0][0])\n",
    "\n",
    "# Prepare training data\n",
    "X_data = np.zeros((len(video_features), max_frames, feature_length))\n",
    "print(X_data.shape)\n",
    "for i, features in enumerate(video_features):\n",
    "    sorted_frames = sorted(features.items(), key=lambda x: x[0])\n",
    "    for j, (_, frame_data) in enumerate(sorted_frames):\n",
    "        X_data[i, j, :] = frame_data[0][0]\n",
    "\n",
    "print(X_data.shape)\n",
    "\n",
    "X_train, X_val, decoder_input_train, decoder_input_val, decoder_target_train, decoder_target_val = train_test_split(X_data, decoder_input_data, decoder_target_data, test_size=0.5, random_state=42)\n",
    "print(\"[INFO] Split data into training and validation sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL CONSTRUCTION ===\n",
    "print(\"[INFO] Constructing the model...\")\n",
    "\n",
    "units = 128\n",
    "embedding_dim = 128\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None, feature_length), name='input_1')\n",
    "encoder_lstm = LSTM(units, return_state=True, name='lstm_1')\n",
    "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,), name='input_2')  # Removed the vocab_size dimension\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim, name='embedding', mask_zero=True)\n",
    "decoder_inputs_embedded = decoder_embedding(decoder_inputs)\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True, name='lstm_2')\n",
    "decoder_lstm_out, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=encoder_states)\n",
    "\n",
    "dropout_rate = 0.5\n",
    "decoder_lstm_out = Dropout(dropout_rate)(decoder_lstm_out)\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax', name='dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm_out)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "from keras.optimizers.legacy import Adam\n",
    "\n",
    "learning_rate = 0.003\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Adjusted loss for integer targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAINING ===\n",
    "print(\"[INFO] Starting training...\")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "history = model.fit([X_train, decoder_input_train], decoder_target_train, validation_data=([X_val, decoder_input_val], decoder_target_val), batch_size=1, epochs=1000, callbacks=[early_stopping])\n",
    "print(\"[INFO] Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('seq2seq_model.h5')\n",
    "\n",
    "# Load tokenizer and max_seq_length\n",
    "with open('../Data/train/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "with open('../Data/train/max_seq_length.pkl', 'rb') as f:\n",
    "    max_seq_length = pickle.load(f)\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_inputs = model.get_layer('input_1').input\n",
    "encoder_lstm = model.get_layer('lstm_1')\n",
    "_, state_h, state_c = encoder_lstm.output\n",
    "encoder_states = [state_h, state_c]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_inputs = model.get_layer('input_2').input\n",
    "decoder_state_input_h = Input(shape=(None,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(None,), name='input_4')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_embedding = model.get_layer('embedding')\n",
    "decoder_lstm = model.get_layer('lstm_2')\n",
    "decoder_lstm_out, state_h_dec, state_c_dec = decoder_lstm(decoder_embedding(decoder_inputs), initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.get_layer('dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm_out)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Decoding sequence function\n",
    "def decode_sequence(input_seq, video_name):\n",
    "    # Encode the input sequence to get the internal state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate an empty target sequence of length 1 with only the start token.\n",
    "    target_seq = np.array(tokenizer.texts_to_sequences(['start'])).reshape(1, 1)\n",
    "    \n",
    "    # Display the video name\n",
    "    print(f\"Video: {video_name}\")\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Sample the next token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word.get(sampled_token_index, '')\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        # Exit condition: either hit max length or find the end token.\n",
    "        if (sampled_word == 'end' or len(decoded_sentence.split()) > max_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence to the last predicted token.\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        \n",
    "        # Update states for the next time step\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return f\"{decoded_sentence.replace(' end', '')}\"  # Optionally remove the end token in the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting data preparation...\n",
      "[INFO] Loaded preprocessed sentences.\n",
      "3\n",
      "[INFO] Video features directory set.\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "[INFO] Loaded video features.\n"
     ]
    }
   ],
   "source": [
    "# === DATA PREPARATION ===\n",
    "print(\"[INFO] Starting data preparation...\")\n",
    "\n",
    "# Load preprocessed sentences\n",
    "preprocessed_file_path = './artifact/preprocessed_sentences.json'\n",
    "with open(preprocessed_file_path, 'r') as f:\n",
    "    preprocessed_data = json.load(f)\n",
    "print(\"[INFO] Loaded preprocessed sentences.\")\n",
    "\n",
    "# Load the saved tokenizer to use its vocabulary size\n",
    "with open('../Data/train/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Load max_seq_length\n",
    "with open('../Data/train/max_seq_length.pkl', 'rb') as f:\n",
    "    max_seq_length = pickle.load(f)\n",
    "\n",
    "print(len(preprocessed_data))\n",
    "\n",
    "preprocessed_data = preprocessed_data[0:100]\n",
    "\n",
    "# Extract the preprocessed sequences directly\n",
    "Y_data = [item['PREPROCESSED_SENTENCE'] for item in preprocessed_data]\n",
    "\n",
    "# Adjust for decoder input and target\n",
    "decoder_input_data = np.array(Y_data)[:, :-1]\n",
    "decoder_target_data = np.array(Y_data)[:, 1:]\n",
    "\n",
    "# Load video features from the directory\n",
    "feature_dir = './artifact/features'\n",
    "print(\"[INFO] Video features directory set.\")\n",
    "\n",
    "video_features = []\n",
    "for item in preprocessed_data:\n",
    "    file_path = os.path.join(feature_dir, f\"{item['SENTENCE_NAME']}.json\")\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            video_features.append(json.load(f))\n",
    "        print(len(video_features))\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load: {file_path}. Error: {e}\")\n",
    "\n",
    "print(len(video_features))\n",
    "print(len(preprocessed_data))\n",
    "\n",
    "print(\"[INFO] Loaded video features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20, 4032)\n",
      "(3, 20, 4032)\n"
     ]
    }
   ],
   "source": [
    "max_frames = max([len(features) for features in video_features])\n",
    "feature_length = len(video_features[0]['frame_0'][0][0])\n",
    "\n",
    "# Prepare training data\n",
    "X_data = np.zeros((len(video_features), max_frames, feature_length))\n",
    "print(X_data.shape)\n",
    "for i, features in enumerate(video_features):\n",
    "    sorted_frames = sorted(features.items(), key=lambda x: x[0])\n",
    "    for j, (_, frame_data) in enumerate(sorted_frames):\n",
    "        X_data[i, j, :] = frame_data[0][0]\n",
    "\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Video: -0JdYlTf9Y8_11-5-rgb_front\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Video: -BFCJ9zmfOo_9-8-rgb_front\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Video: -AFID_P6YU0_15-8-rgb_front\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "actual_sentences = []\n",
    "predicted_sentences = []\n",
    "for i in range(len(X_data)):\n",
    "    sample_index = i\n",
    "    input_seq = X_data[sample_index:sample_index+1]\n",
    "    video_name = preprocessed_data[sample_index]['SENTENCE_NAME']\n",
    "    actual_sentence = preprocessed_data[sample_index]['SENTENCE_DESCRIPTION']\n",
    "    predicted_sentence = decode_sequence(input_seq, video_name)\n",
    "    actual_sentences.append(actual_sentence)\n",
    "    predicted_sentences.append(predicted_sentence.replace('start', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sentence: It's really, what you get for your dollar.\n",
      "Predicted Sentence: its really what you get for your dollar\n",
      "Actual Sentence: And there we go; it's coming off nicely.\n",
      "Predicted Sentence: and there we go its coming off nicely\n",
      "Actual Sentence: And it'll do well in drought conditions.\n",
      "Predicted Sentence: and itll do well in drought conditions\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Actual Sentence:\", actual_sentences[i])\n",
    "    print(\"Predicted Sentence:\", predicted_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
