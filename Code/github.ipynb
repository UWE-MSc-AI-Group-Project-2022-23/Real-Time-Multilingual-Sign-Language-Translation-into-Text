{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the original JSON data\n",
    "with open('../Dataset/train.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Initialize lists for labels and paths\n",
    "filtered_labels = []\n",
    "filtered_paths = []\n",
    "\n",
    "filtered_data = []\n",
    "filtered_ids = []\n",
    "video_paths = []\n",
    "\n",
    "# Filter the data based on SENTENCE_DURATION between 2 and 3 seconds\n",
    "for item in data:\n",
    "    if 2.0 < item['SENTENCE_DURATION'] < 3.0:\n",
    "        filtered_data.append(item)\n",
    "        filtered_labels.append(\"<bos> \" + item['SENTENCE_DESCRIPTION'] + \" <eos>\")  # Assuming 'SENTENCE_DESCRIPTION' contains labels\n",
    "        filtered_paths.append(f\"./3ktrain/features/{item['SENTENCE_NAME']}.npy\")\n",
    "        filtered_ids.append(item['SENTENCE_NAME'])\n",
    "        video_paths.append(f\"../../Dataset/train/videos/{item['SENTENCE_NAME']}.mp4\")\n",
    "\n",
    "# filtered_data = filtered_data[0:50]\n",
    "\n",
    "print(len(filtered_data))\n",
    "\n",
    "# Write the filtered labels and paths to separate JSON files\n",
    "with open('3ktrain.json', 'w') as labels_file:\n",
    "    json.dump(filtered_data, labels_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MLFlow\n",
    "\n",
    "input_json_file = './3ktrain.json'\n",
    "output_folder = './3ktrain/'\n",
    "# processing_steps = [\"crop\", \"reduce_noise\", \"add_noise\", \"rotate\", \"brightness\", \"contrast\", \"saturation\"]\n",
    "\n",
    "processor = MLFlow(input_json_file, output_folder)\n",
    "vectors_df = processor.process_video_and_extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "videoId = []\n",
    "videoSeq = []\n",
    "videoSeq_raw = []\n",
    "videoId_raw = []\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(filtered_data)):\n",
    "    if os.path.exists(filtered_paths[i]):\n",
    "        features.append(filtered_paths[i])\n",
    "        videoId_raw.append(filtered_ids[i])\n",
    "        videoSeq_raw.append(filtered_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = {}\n",
    "for i in range(0, len(filtered_data)):\n",
    "    f = np.load(filtered_paths[i])\n",
    "    f = f.reshape(-1, int(np.prod(f.shape[1:])))\n",
    "    if f.shape[1] == 487872:\n",
    "        x_data[filtered_paths[i][19:-4]] = f\n",
    "        videoId.append(videoId_raw[i])\n",
    "        videoSeq.append(videoSeq_raw[i])\n",
    "\n",
    "print(len(x_data))\n",
    "print(len(videoId))\n",
    "print(len(videoSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(videoSeq[1], videoId[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens = max(len(i) for i in filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del filtered_labels, filtered_paths, filtered_data, filtered_ids, video_paths, videoSeq_raw, videoId_raw, features, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_decoder_tokens)\n",
    "tokenizer.fit_on_texts(videoSeq)\n",
    "# word_index = tokenizer.word_index   \n",
    "print ('Convert to index sequences.')\n",
    "train_sequences = tokenizer.texts_to_sequences(videoSeq)\n",
    "train_sequences = pad_sequences(train_sequences, padding='post',truncating='post')\n",
    "train_sequences = np.array(train_sequences)\n",
    "train_sequences = pad_sequences(train_sequences, padding='post',truncating='post')\n",
    "print(train_sequences.shape)\n",
    "# max_seq_length = train_sequences.shape[1]\n",
    "filesize = len(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "encoder_input_data = []\n",
    "decoder_input_data = []\n",
    "decoder_target_data = []\n",
    "X_data = []\n",
    "y_data = []\n",
    "for idx in range(0, filesize):\n",
    "    if len(x_data[videoId[idx]])==71:\n",
    "        encoder_input_data.append(x_data[videoId[idx]])\n",
    "        y = to_categorical(train_sequences[idx], num_decoder_tokens)\n",
    "        decoder_input_data.append(y[:-1])\n",
    "        decoder_target_data.append(y[1:])\n",
    "encoder_input_data = np.array(encoder_input_data)\n",
    "decoder_input_data = np.array(decoder_input_data)\n",
    "decoder_target_data = np.array(decoder_target_data)\n",
    "\n",
    "time_steps_decoder = decoder_input_data.shape[1]\n",
    "\n",
    "print(encoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_data, train_sequences, filesize, videoSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "# from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# simple_model = Sequential()\n",
    "\n",
    "# simple_model.add(LSTM(32, input_shape=(60, 487872), return_sequences=True))\n",
    "\n",
    "# simple_model.add(LSTM(32))\n",
    "\n",
    "# simple_model.add(Dense(num_decoder_tokens, activation='softmax'))\n",
    "\n",
    "# simple_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# encoder_input_data_train, encoder_input_data_test, decoder_input_data_train, decoder_input_data_test = train_test_split(encoder_input_data, decoder_target_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_model.fit(encoder_input_data_train, decoder_input_data_train, epochs=2, batch_size=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = simple_model.evaluate(encoder_input_data_test, decoder_input_data_test, verbose=0)\n",
    "\n",
    "# print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, Permute, Reshape, Activation, Flatten\n",
    "\n",
    "time_steps_encoder = 71\n",
    "num_encoder_tokens = 487872\n",
    "latent_dim = 8\n",
    "\n",
    "encoder_inputs = Input(shape=(time_steps_encoder, num_encoder_tokens), name=\"encoder_inputs\")\n",
    "encoder = LSTM(latent_dim, return_state=True,return_sequences=True, name='endcoder_lstm')\n",
    "_, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(time_steps_decoder, num_decoder_tokens), name= \"decoder_inputs\")\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='relu', name='decoder_relu')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model.compile(metrics=['accuracy'], optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "print(1)\n",
    "\n",
    "encoder_input_data_train, encoder_input_data_test, decoder_input_data_train, decoder_input_data_test, decoder_target_data_train, decoder_target_data_test = train_test_split(encoder_input_data, decoder_input_data, decoder_target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([encoder_input_data_train, decoder_input_data_train], decoder_target_data_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate([encoder_input_data_test, decoder_input_data_test], decoder_target_data_test, verbose=0)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "encoder_model.summary()\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "\n",
    "inf_encoder_model = encoder_model\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "inf_decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "inf_decoder_model.set_weights(decoder_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder_model.save(os.path.join('./', 'inf_encoder_model.keras'))\n",
    "inf_decoder_model.save(os.path.join('./', 'inf_decoder_model.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functools, operator\n",
    "\n",
    "# max_propablity = -1\n",
    "# decode_seq = [] \n",
    "\n",
    "# def decode_sequence2bs(input_seq):\n",
    "#     states_value = inf_encoder_model.predict(input_seq)\n",
    "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#     target_seq[0, 0, tokenizer.word_index['bos']] = 1\n",
    "#     beam_search(target_seq, states_value,[],[],0)\n",
    "#     return decode_seq\n",
    "\n",
    "# def beam_search(target_seq, states_value, prob,  path, lens):\n",
    "#     global decode_seq\n",
    "#     global max_propablity\n",
    "#     node = 2\n",
    "#     output_tokens, h, c = inf_decoder_model.predict(\n",
    "#         [target_seq] + states_value)\n",
    "#     output_tokens = output_tokens.reshape((num_decoder_tokens))\n",
    "#     sampled_token_index = output_tokens.argsort()[-node:][::-1]\n",
    "#     states_value = [h, c]\n",
    "#     for i in range(node):\n",
    "#         if sampled_token_index[i] == 0:\n",
    "#             sampled_char = ''\n",
    "#         else:\n",
    "#             sampled_char = list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(sampled_token_index[i])]\n",
    "#         MAX_LEN = 9\n",
    "#         if(sampled_char != 'eos' and lens <= MAX_LEN):\n",
    "#             p = output_tokens[sampled_token_index[i]]\n",
    "#             if(sampled_char == ''):\n",
    "#                 p = 1\n",
    "#             prob_new = list(prob)\n",
    "#             prob_new.append(p)\n",
    "#             path_new = list(path)\n",
    "#             path_new.append(sampled_char)\n",
    "#             target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#             target_seq[0, 0, sampled_token_index[i]] = 1.\n",
    "#             beam_search(target_seq, states_value, prob_new, path_new, lens+1)\n",
    "#         else:\n",
    "#             p = output_tokens[sampled_token_index[i]]\n",
    "#             prob_new = list(prob)\n",
    "#             prob_new.append(p)\n",
    "#             p = functools.reduce(operator.mul, prob_new, 1)\n",
    "#             if(p > max_propablity):\n",
    "#                 decode_seq = path\n",
    "#                 max_propablity = p\n",
    "\n",
    "# def decoded_sentence_tuning(decoded_sentence):\n",
    "#     decode_str = []\n",
    "#     filter_string = ['bos', 'eos']\n",
    "#     unigram = {}\n",
    "#     last_string = \"\"\n",
    "#     for idx2, c in enumerate(decoded_sentence):\n",
    "#         if c in unigram:\n",
    "#             unigram[c] += 1\n",
    "#         else:\n",
    "#             unigram[c] = 1\n",
    "#         if(last_string == c and idx2 > 0):\n",
    "#             continue\n",
    "#         if c in filter_string:\n",
    "#             continue\n",
    "#         if len(c) > 0:\n",
    "#             decode_str.append(c)\n",
    "#         if idx2 > 0:\n",
    "#             last_string = c\n",
    "#     return decode_str\n",
    "\n",
    "# def test():\n",
    "#     X_test = []\n",
    "#     X_test_filename = []\n",
    "\n",
    "#     for i in range(0, 1):\n",
    "#         f = np.load(os.path.join(f\"./train/features/{videoId[i]}.npy\"))\n",
    "#         X_test.append(f)\n",
    "#         X_test_filename.append(videoId[i])\n",
    "#     X_test = np.array(X_test)\n",
    "\n",
    "#     with open(os.path.join('./', 'test_output.txt'), 'w') as file:\n",
    "#         for idx, x in enumerate(X_test): \n",
    "#             file.write(X_test_filename[idx]+',')\n",
    "#             decoded_sentence = decode_sequence2bs(x.reshape(-1, 48, 487872))\n",
    "#             decode_str = decoded_sentence_tuning(decoded_sentence)\n",
    "#             for d in decode_str:\n",
    "#                 file.write(d + ' ')\n",
    "#             file.write('\\n')\n",
    "#             max_propablity = -1\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import functools\n",
    "# import operator\n",
    "\n",
    "# max_probability = -1\n",
    "# decode_seq = []\n",
    "\n",
    "# def decode_sequence_teacher_forcing(input_seq):\n",
    "#     states_value = inf_encoder_model.predict(input_seq)\n",
    "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#     target_seq[0, 0, tokenizer.word_index['bos']] = 1\n",
    "\n",
    "#     # Initialize the output sequence\n",
    "#     output_seq = np.zeros((1, 195, num_decoder_tokens))\n",
    "\n",
    "#     for t in range(195):\n",
    "#         output_tokens, h, c = inf_decoder_model.predict([target_seq] + states_value)\n",
    "#         output_seq[0, t, :] = output_tokens[0, 0, :]\n",
    "\n",
    "#         # Sample the next token from the output\n",
    "#         sampled_token_index = np.argmax(output_tokens)\n",
    "#         sampled_char = list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(sampled_token_index)]\n",
    "        \n",
    "#         if sampled_char == 'eos':\n",
    "#             break\n",
    "\n",
    "#         # Update the target sequence for the next time step\n",
    "#         target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#         target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "#         # Update states\n",
    "#         states_value = [h, c]\n",
    "\n",
    "#         print(f\"Step {t + 1}: Predicted token: {sampled_char}\")\n",
    "\n",
    "#     return output_seq\n",
    "\n",
    "# def test():\n",
    "#     X_test = []\n",
    "#     X_test_filename = []\n",
    "\n",
    "#     for i in range(0, 10):\n",
    "#         f = np.load(os.path.join(f\"./train/features/{videoId[i]}.npy\"))\n",
    "#         X_test.append(f)\n",
    "#         X_test_filename.append(videoId[i])\n",
    "#     # X_test = np.array(X_test)\n",
    "\n",
    "#     with open(os.path.join('./', 'test_output.txt'), 'w') as file:\n",
    "#         for x in range(0, len(X_test)): \n",
    "#             file.write(X_test_filename[x]+',')\n",
    "#             output_seq = decode_sequence_teacher_forcing(X_test[x].reshape(-1, 48, 487872))\n",
    "\n",
    "#             # Process the output sequence\n",
    "#             decoded_sentence = []\n",
    "#             for t in range(195):\n",
    "#                 sampled_token_index = np.argmax(output_seq[0, t, :])\n",
    "#                 sampled_char = list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(sampled_token_index)]\n",
    "#                 if sampled_char == 'eos':\n",
    "#                     break\n",
    "#                 if len(sampled_char) > 0:\n",
    "#                     decoded_sentence.append(sampled_char)\n",
    "\n",
    "#             decode_str = decoded_sentence_tuning(decoded_sentence)\n",
    "#             for d in decode_str:\n",
    "#                 file.write(d + ' ')\n",
    "#             file.write('\\n')\n",
    "\n",
    "# test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea8cbe8d418dcee82a385562f6c14c3de2c4e19feb50c3f5f3dfe742635c4125"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
