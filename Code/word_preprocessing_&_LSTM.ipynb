{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the Words\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from packaging.version import parse\n",
    "\n",
    "class WordPreprocessor:\n",
    "    def __init__(self, dataset_dir, csv_path):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.csv_path = csv_path\n",
    "        # Check sklearn version to decide on the argument name\n",
    "        if parse(sklearn_version) >= parse(\"1.2\"):\n",
    "            self.onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "        else:\n",
    "            self.onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def preprocess_words(self):\n",
    "        # Step 1: Read the CSV file\n",
    "        data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Filter out words for videos not in the ./train/videos directory\n",
    "        available_videos = set(os.listdir(os.path.join(self.dataset_dir, 'videos')))\n",
    "        data = data[data['video_name'].isin(available_videos)]\n",
    "        \n",
    "        words = data['word'].values\n",
    "        video_names = data['video_name'].values\n",
    "\n",
    "        # Step 2: Encode words into numerical labels\n",
    "        labels = self.label_encoder.fit_transform(words)\n",
    "        \n",
    "        # Store the mapping of class names to labels\n",
    "        self.class_to_label_mapping = dict(zip(words, labels))\n",
    "        print(self.class_to_label_mapping)\n",
    "        # Step 3: One-hot encode the labels (optional)\n",
    "        labels_reshaped = labels.reshape(len(labels), 1)\n",
    "        onehot_encoded = self.onehot_encoder.fit_transform(labels_reshaped)\n",
    "\n",
    "        return video_names, labels, onehot_encoded\n",
    "\n",
    "    def decode_labels(self, labels):\n",
    "        return self.label_encoder.inverse_transform(labels)\n",
    "\n",
    "    def decode_onehot(self, onehot_encoded):\n",
    "        labels = self.onehot_encoder.inverse_transform(onehot_encoded)\n",
    "        return self.label_encoder.inverse_transform(labels.flatten())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    word_processor = WordPreprocessor('./train', './train/video_dataset.csv')\n",
    "    video_names, labels, onehot_encoded = word_processor.preprocess_words()\n",
    "\n",
    "    # Example usage of decode functions\n",
    "    decoded_labels = word_processor.decode_labels(labels)\n",
    "    decoded_onehot = word_processor.decode_onehot(onehot_encoded)\n",
    "    print(video_names + decoded_labels)\n",
    "    print(\"Decoded labels:\", decoded_labels)\n",
    "    print(\"Decoded onehot:\", decoded_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM - Model Training\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constants\n",
    "FEATURE_DIM = 4032\n",
    "SEQUENCE_LENGTH = 101\n",
    "\n",
    "class SignLanguageModel:\n",
    "    def __init__(self, feature_dir, labels):\n",
    "        self.feature_dir = feature_dir\n",
    "        self.labels = labels\n",
    "        self.N_CLASSES = len(np.unique(list(labels.values())))\n",
    "        self.model = self.initialize_model(self.N_CLASSES)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_model(N_CLASSES):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(256, input_shape=(SEQUENCE_LENGTH, FEATURE_DIM), return_sequences=True))\n",
    "        model.add(LSTM(128))\n",
    "        model.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, epochs=50, batch_size=32):\n",
    "        X, y = self.load_data()\n",
    "        \n",
    "        # Verify if X and y have data before training\n",
    "        if len(X) == 0 or len(y) == 0:\n",
    "            print(\"No valid data available for training!\")\n",
    "            return\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.feature_dir, 'r') as hf:\n",
    "            video_names = list(hf.keys())\n",
    "            print(\"Video names in NASNetLarge_feature_vectors.hdf5:\", video_names)  \n",
    "            X = []\n",
    "            y = []\n",
    "\n",
    "            for video_name in video_names:\n",
    "                if video_name not in self.labels:\n",
    "                    print(f\"Warning: {video_name} not found in labels dictionary!\")\n",
    "                    continue\n",
    "                \n",
    "                # Print mapping for verification\n",
    "                print(f\"Mapping: {video_name} -> {self.labels[video_name]}\")\n",
    "\n",
    "                features = np.array(hf[video_name]).reshape(-1, FEATURE_DIM)\n",
    "\n",
    "                if features.shape[0] < SEQUENCE_LENGTH:\n",
    "                    zero_padding = np.zeros((SEQUENCE_LENGTH - features.shape[0], FEATURE_DIM))\n",
    "                    features = np.vstack((features, zero_padding))\n",
    "                elif features.shape[0] > SEQUENCE_LENGTH:\n",
    "                    features = features[:SEQUENCE_LENGTH]\n",
    "\n",
    "                X.append(features)\n",
    "                y.append(self.labels[video_name])\n",
    "            X = np.array(X)\n",
    "            y = to_categorical(np.array(y), num_classes=self.N_CLASSES)\n",
    "        return X, y\n",
    "\n",
    "    def save_model(self, path_to_save):\n",
    "        self.model.save(path_to_save, save_format=\"tf\")\n",
    "        print(f\"Model saved to {path_to_save}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    word_processor = WordPreprocessor('./train', './train/video_dataset.csv')\n",
    "    video_names, labels, _ = word_processor.preprocess_words()\n",
    "    labels_dict = dict(zip(video_names, labels))\n",
    "    \n",
    "    print(\"Labels dictionary:\", labels_dict)  \n",
    "\n",
    "    sl_model = SignLanguageModel('./train/NASNetLarge_feature_vectors.hdf5', labels_dict)\n",
    "    sl_model.train(epochs=50, batch_size=16)\n",
    "    sl_model.save_model('./trained_sign_language_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Constants\n",
    "FEATURE_DIM = 4032\n",
    "SEQUENCE_LENGTH = 101\n",
    "\n",
    "def load_data_for_prediction(feature_dir, video_name):\n",
    "    with h5py.File(feature_dir, 'r') as hf:\n",
    "        if video_name not in hf.keys():\n",
    "            print(f\"Warning: {video_name} not found in the feature file!\")\n",
    "            return None\n",
    "\n",
    "        features = np.array(hf[video_name]).reshape(-1, FEATURE_DIM)\n",
    "\n",
    "        if features.shape[0] < SEQUENCE_LENGTH:\n",
    "            zero_padding = np.zeros((SEQUENCE_LENGTH - features.shape[0], FEATURE_DIM))\n",
    "            features = np.vstack((features, zero_padding))\n",
    "        elif features.shape[0] > SEQUENCE_LENGTH:\n",
    "            features = features[:SEQUENCE_LENGTH]\n",
    "        \n",
    "        # Reshaping for model input\n",
    "        features = features.reshape(1, SEQUENCE_LENGTH, FEATURE_DIM)\n",
    "    return features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load model\n",
    "    model_path = './trained_sign_language_model.keras'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load the training data\n",
    "    word_processor = WordPreprocessor('./train', './train/video_dataset.csv')\n",
    "    video_names, labels, _ = word_processor.preprocess_words()\n",
    "    labels_dict = dict(zip(video_names, labels))\n",
    "    \n",
    "    # Create a reverse mapping for class to label\n",
    "    label_to_class_mapping = word_processor.class_to_label_mapping\n",
    "    class_to_label_mapping = {v: k.strip() for k, v in label_to_class_mapping.items()}\n",
    "\n",
    "    # Make predictions for the entire training dataset\n",
    "    for sample_video_name in video_names:\n",
    "        print(f\"Making prediction for video: {sample_video_name}\")\n",
    "        \n",
    "        sample_data = load_data_for_prediction('./train/NASNetLarge_feature_vectors.hdf5', sample_video_name)\n",
    "        if sample_data is not None:\n",
    "            prediction = model.predict(sample_data)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "            \n",
    "            actual_class = labels_dict[sample_video_name]\n",
    "            actual_label = class_to_label_mapping[actual_class]\n",
    "            predicted_label = class_to_label_mapping[predicted_class]\n",
    "            \n",
    "            print(f\"Actual Class & Label for {sample_video_name}: {actual_class} ({actual_label})\")\n",
    "            print(f\"Predicted Class & Label for {sample_video_name}: {predicted_class} ({predicted_label})\")\n",
    "            print('-'*50) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
